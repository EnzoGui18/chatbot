{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Cv5SDixlSf31rGAmEosyBKggz38fgbX_",
      "authorship_tag": "ABX9TyPPDdTWMEZxY+6yAH/leyIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "965b9b7648874f998c112c7ff441d61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_d347bca6b4f6468b92d00f70fd69dba6"
          }
        },
        "600b1493f4e849c0b716291188c2fe8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b924d7957a040c99c56ec8e021f70f3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bc8b0642734f44878e66014e293caa84",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "461e262df709423a9c22cac7e7b5ddb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4b0423bed5e04dcdadb5c605fbcc8904",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2d9901757c914c98b7aaa40fba890429",
            "value": ""
          }
        },
        "386bef3a75c54815a041cbdc6a1e8fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_806dfbb4d15a4393b1f944cf41fba6fc",
            "style": "IPY_MODEL_aeac5fd20d8a4a48b6400e4577fb63d4",
            "value": true
          }
        },
        "511100f37b204a7ab8bb100f2fd2115c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8800840705584d8d91bf215882c2af6d",
            "style": "IPY_MODEL_6eb8a7b1ade1474285204d92678f7fe3",
            "tooltip": ""
          }
        },
        "d4033a08bad147178998b517bf090c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d4c482f7ba4e809db7fc0e5e906a09",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2023479ea3ef49409e345f4a990bb9db",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d347bca6b4f6468b92d00f70fd69dba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0b924d7957a040c99c56ec8e021f70f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8b0642734f44878e66014e293caa84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b0423bed5e04dcdadb5c605fbcc8904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9901757c914c98b7aaa40fba890429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806dfbb4d15a4393b1f944cf41fba6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeac5fd20d8a4a48b6400e4577fb63d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8800840705584d8d91bf215882c2af6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb8a7b1ade1474285204d92678f7fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "12d4c482f7ba4e809db7fc0e5e906a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2023479ea3ef49409e345f4a990bb9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b8f6b6516244d3ebb1ed5e16608d608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51479be971854d358514aaa50d37aec0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7dff2b8d1d0247ea849efda1153d3bd0",
            "value": "Connecting..."
          }
        },
        "51479be971854d358514aaa50d37aec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dff2b8d1d0247ea849efda1153d3bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5019b071b19f4eeebee6a23b9abdedbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db4e614a44d64c2196331e94594c73e9",
              "IPY_MODEL_3bae76a5478343a392553a3b6a695437",
              "IPY_MODEL_b37637ff468d4248ac03db476095b7bc"
            ],
            "layout": "IPY_MODEL_687ec20ca6e14763b738d8cc06e26084"
          }
        },
        "db4e614a44d64c2196331e94594c73e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_727d4b1148444a85b35ff8c840ba2792",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e17844ff97954765892546f3bbbb50dd",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "3bae76a5478343a392553a3b6a695437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d84f45bd6a43659b2594a9c40c2cd3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9502c795426444799d13bcab557aea01",
            "value": 4
          }
        },
        "b37637ff468d4248ac03db476095b7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd5cbf7a62a4111a1639e93c545d3e3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_657f69c6377f4883a0fed19dbe9f04df",
            "value": "â€‡4/4â€‡[01:21&lt;00:00,â€‡17.17s/it]"
          }
        },
        "687ec20ca6e14763b738d8cc06e26084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "727d4b1148444a85b35ff8c840ba2792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17844ff97954765892546f3bbbb50dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36d84f45bd6a43659b2594a9c40c2cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9502c795426444799d13bcab557aea01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcd5cbf7a62a4111a1639e93c545d3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657f69c6377f4883a0fed19dbe9f04df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnzoGui18/chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8P131sNzwep",
        "outputId": "3653d744-5f54-48ac-b38f-c9fbc70d03c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ambiente completo para execuÃ§Ã£o local no Colab instalado!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \\\n",
        "    transformers \\\n",
        "    torch \\\n",
        "    accelerate \\\n",
        "    bitsandbytes \\\n",
        "    sentence-transformers \\\n",
        "    faiss-cpu \\\n",
        "    gradio \\\n",
        "    pdfplumber \\\n",
        "    beautifulsoup4 \\\n",
        "    requests \\\n",
        "    langchain \\\n",
        "    langchain-community \\\n",
        "    langchain-text-splitters\n",
        "\n",
        "print(\"âœ… Ambiente completo para execuÃ§Ã£o local no Colab instalado!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Cole seu token de acesso do Hugging Face\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "965b9b7648874f998c112c7ff441d61c",
            "600b1493f4e849c0b716291188c2fe8f",
            "461e262df709423a9c22cac7e7b5ddb8",
            "386bef3a75c54815a041cbdc6a1e8fd1",
            "511100f37b204a7ab8bb100f2fd2115c",
            "d4033a08bad147178998b517bf090c17",
            "d347bca6b4f6468b92d00f70fd69dba6",
            "0b924d7957a040c99c56ec8e021f70f3",
            "bc8b0642734f44878e66014e293caa84",
            "4b0423bed5e04dcdadb5c605fbcc8904",
            "2d9901757c914c98b7aaa40fba890429",
            "806dfbb4d15a4393b1f944cf41fba6fc",
            "aeac5fd20d8a4a48b6400e4577fb63d4",
            "8800840705584d8d91bf215882c2af6d",
            "6eb8a7b1ade1474285204d92678f7fe3",
            "12d4c482f7ba4e809db7fc0e5e906a09",
            "2023479ea3ef49409e345f4a990bb9db",
            "6b8f6b6516244d3ebb1ed5e16608d608",
            "51479be971854d358514aaa50d37aec0",
            "7dff2b8d1d0247ea849efda1153d3bd0"
          ]
        },
        "id": "0NR7Tu-o1UNh",
        "outputId": "4c2b3c23-66e7-4c7b-e18e-dba110e0ced1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "965b9b7648874f998c112c7ff441d61c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Define o dispositivo como a GPU do Colab\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# --- 1. Carregar o Modelo de Embedding ---\n",
        "print(\"\\nCarregando modelo de embedding 'Legal-BERTimbau-large'...\")\n",
        "embedding_model = SentenceTransformer('rufimelo/Legal-BERTimbau-large', device=device)\n",
        "print(\"âœ… Modelo de Embedding carregado.\")\n",
        "\n",
        "# --- 2. Carregar o Modelo de Linguagem (LLM) com QuantizaÃ§Ã£o ---\n",
        "LLM_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# ConfiguraÃ§Ã£o de quantizaÃ§Ã£o correta\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print(f\"\\nCarregando LLM '{LLM_MODEL_NAME}' (pode demorar)...\")\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(\"âœ… LLM carregado com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "5019b071b19f4eeebee6a23b9abdedbf",
            "db4e614a44d64c2196331e94594c73e9",
            "3bae76a5478343a392553a3b6a695437",
            "b37637ff468d4248ac03db476095b7bc",
            "687ec20ca6e14763b738d8cc06e26084",
            "727d4b1148444a85b35ff8c840ba2792",
            "e17844ff97954765892546f3bbbb50dd",
            "36d84f45bd6a43659b2594a9c40c2cd3",
            "9502c795426444799d13bcab557aea01",
            "fcd5cbf7a62a4111a1639e93c545d3e3",
            "657f69c6377f4883a0fed19dbe9f04df"
          ]
        },
        "id": "poVPfYd81eAq",
        "outputId": "0f0d6289-551c-4e91-edec-10b8e146b8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n",
            "\n",
            "Carregando modelo de embedding 'Legal-BERTimbau-large'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name rufimelo/Legal-BERTimbau-large. Creating a new one with mean pooling.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at rufimelo/Legal-BERTimbau-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Modelo de Embedding carregado.\n",
            "\n",
            "Carregando LLM 'meta-llama/Meta-Llama-3-8B-Instruct' (pode demorar)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5019b071b19f4eeebee6a23b9abdedbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LLM carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "import pdfplumber\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class PDFReader:\n",
        "    def __init__(self, data_dir: str = \"data\"):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self._create_directory()\n",
        "    def _create_directory(self) -> None:\n",
        "        if not self.data_dir.exists(): self.data_dir.mkdir(parents=True, exist_ok=True)\n",
        "    def _find_pdfs(self) -> List[Path]:\n",
        "        return list(self.data_dir.glob(\"*.pdf\"))\n",
        "    def _extract_text(self, pdf_path: Path) -> str:\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text(); text += page_text + \"\\n\" if page_text else \"\"\n",
        "        except Exception as e: print(f\"âŒ Erro ao processar {pdf_path.name}: {e}\")\n",
        "        return text\n",
        "    def read_all_pdfs(self) -> Dict[str, str]:\n",
        "        pdf_files = self._find_pdfs()\n",
        "        if not pdf_files: print(f\"âŒ Nenhum PDF encontrado em '{self.data_dir}'\"); return {}\n",
        "        documents = {}; print(f\"ðŸ”Ž Processando {len(pdf_files)} arquivo(s) PDF...\")\n",
        "        for pdf_path in pdf_files:\n",
        "            text = self._extract_text(pdf_path)\n",
        "            if text.strip(): documents[pdf_path.name] = text; print(f\"ðŸ“„âœ” {pdf_path.name}\")\n",
        "        return documents\n",
        "\n",
        "class DocumentLoader:\n",
        "    def __init__(self, data_dir: str = \"data\"):\n",
        "        self.pdf_reader = PDFReader(data_dir); self.documents = {}\n",
        "    def load_pdfs(self):\n",
        "        print(\"\\nðŸ“„ Carregando PDFs...\"); pdf_docs = self.pdf_reader.read_all_pdfs(); self.documents.update(pdf_docs)\n",
        "    def load_all(self):\n",
        "        self.load_pdfs()\n",
        "        print(\"\\n\" + \"=\"*30 + \"\\nðŸ“Š Resumo do Carregamento:\")\n",
        "        print(f\"  - Total de documentos: {len(self.documents)}\")\n",
        "        print(f\"  - Total de caracteres: {sum(len(c) for c in self.documents.values())}\")\n",
        "        print(\"=\"*30)\n",
        "\n",
        "print(\"âœ… Classes PDFReader e DocumentLoader definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWzb-4SY42_i",
        "outputId": "99b181a0-9d9c-4a98-82d5-341ada5d2a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Classes PDFReader e DocumentLoader definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text); text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    lines = text.split('\\n'); clean_lines = [line.strip() for line in lines if len(line.strip()) > 10]\n",
        "    return \"\\n\".join(clean_lines)\n",
        "\n",
        "def create_chunks(documents: Dict[str, str], chunk_size=1000, chunk_overlap=200) -> Dict[str, List[str]]:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunked_docs = {}; print(\"\\nìª¼ Dividindo documentos em chunks...\")\n",
        "    for doc_name, content in documents.items():\n",
        "        chunks = text_splitter.split_text(content)\n",
        "        chunked_docs[doc_name] = chunks\n",
        "        print(f\"  - '{doc_name}' dividido em {len(chunks)} chunks.\")\n",
        "    return chunked_docs\n",
        "\n",
        "print(\"âœ… FunÃ§Ãµes clean_text e create_chunks definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-QNjYpt45qI",
        "outputId": "376b9262-8b33-458a-d023-e943fe5fd929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FunÃ§Ãµes clean_text e create_chunks definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carregar os documentos\n",
        "loader = DocumentLoader()\n",
        "loader.load_all()\n",
        "raw_documents = loader.documents\n",
        "\n",
        "# 2. Limpar os textos\n",
        "cleaned_documents = {doc_name: clean_text(content) for doc_name, content in raw_documents.items()}\n",
        "print(\"\\nâœ¨ Textos limpos com sucesso!\")\n",
        "\n",
        "# 3. Dividir em Chunks\n",
        "chunked_documents = create_chunks(cleaned_documents)\n",
        "print(\"\\nâœ… Pipeline de preparaÃ§Ã£o de dados concluÃ­do!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZyRVY8y6d7x",
        "outputId": "93db2f24-bb7c-40fd-9c4a-211f3592f0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“„ Carregando PDFs...\n",
            "ðŸ”Ž Processando 3 arquivo(s) PDF...\n",
            "ðŸ“„âœ” Consumidor.pdf\n",
            "ðŸ“„âœ” civil.pdf\n",
            "ðŸ“„âœ” trabalhista.pdf\n",
            "\n",
            "==============================\n",
            "ðŸ“Š Resumo do Carregamento:\n",
            "  - Total de documentos: 3\n",
            "  - Total de caracteres: 2125765\n",
            "==============================\n",
            "\n",
            "âœ¨ Textos limpos com sucesso!\n",
            "\n",
            "ìª¼ Dividindo documentos em chunks...\n",
            "  - 'Consumidor.pdf' dividido em 104 chunks.\n",
            "  - 'civil.pdf' dividido em 822 chunks.\n",
            "  - 'trabalhista.pdf' dividido em 1721 chunks.\n",
            "\n",
            "âœ… Pipeline de preparaÃ§Ã£o de dados concluÃ­do!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ©lula 8 (Corrigida e Completa)\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # <-- IMPORTANTE: A importaÃ§Ã£o do nosso \"adaptador\"\n",
        "\n",
        "# O FAISS prefere uma lista de objetos 'Document' do LangChain.\n",
        "# Esta parte do cÃ³digo jÃ¡ estÃ¡ correta.\n",
        "documents_for_faiss = []\n",
        "for doc_name, chunks in chunked_documents.items():\n",
        "    for chunk_text in chunks:\n",
        "        documents_for_faiss.append(\n",
        "            Document(page_content=chunk_text, metadata={\"source\": doc_name})\n",
        "        )\n",
        "\n",
        "print(f\"\\nTotal de {len(documents_for_faiss)} chunks preparados para vetorizaÃ§Ã£o.\")\n",
        "\n",
        "# --- A CORREÃ‡ÃƒO ESTÃ AQUI ---\n",
        "# 1. Criamos o \"adaptador\" compatÃ­vel com o LangChain.\n",
        "# Em vez de passar nosso 'embedding_model' diretamente, nÃ³s instanciamos\n",
        "# a classe HuggingFaceEmbeddings, especificando o nome do modelo.\n",
        "langchain_embedder = HuggingFaceEmbeddings(\n",
        "    model_name='rufimelo/Legal-BERTimbau-large',\n",
        "    model_kwargs={'device': device} # Garante que ele use a GPU que jÃ¡ definimos\n",
        ")\n",
        "print(\"Adaptador de embedding para LangChain criado.\")\n",
        "\n",
        "print(\"\\nVetorizando os documentos e criando o Ã­ndice FAISS...\")\n",
        "\n",
        "# 2. Usamos o novo 'langchain_embedder' para criar o vector_store\n",
        "vector_store = FAISS.from_documents(documents_for_faiss, langchain_embedder)\n",
        "\n",
        "print(\"âœ… Banco de dados vetorial FAISS criado com sucesso!\")"
      ],
      "metadata": {
        "id": "5MdZ1d2N7NPf",
        "outputId": "6a874843-3544-40fb-9661-319a48f512a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total de 2647 chunks preparados para vetorizaÃ§Ã£o.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-715655568.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  langchain_embedder = HuggingFaceEmbeddings(\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name rufimelo/Legal-BERTimbau-large. Creating a new one with mean pooling.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at rufimelo/Legal-BERTimbau-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptador de embedding para LangChain criado.\n",
            "\n",
            "Vetorizando os documentos e criando o Ã­ndice FAISS...\n",
            "âœ… Banco de dados vetorial FAISS criado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"Preparando o LLM para integraÃ§Ã£o com o LangChain...\")\n",
        "\n",
        "# Cria um pipeline de geraÃ§Ã£o de texto do Transformers\n",
        "# Este Ã© o invÃ³lucro padrÃ£o para usar modelos como o Llama 3\n",
        "text_generation_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=llm_model,\n",
        "    tokenizer=llm_tokenizer,\n",
        "    max_new_tokens=1024, # Define o tamanho mÃ¡ximo da resposta\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# \"Embrulha\" o pipeline na classe compatÃ­vel com LangChain\n",
        "llm_for_chain = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "print(\"âœ… LLM pronto para ser usado na cadeia RAG!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKgmhkQJKsFB",
        "outputId": "625ad73a-4913-4b02-aee6-8b7d4202dacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparando o LLM para integraÃ§Ã£o com o LangChain...\n",
            "âœ… LLM pronto para ser usado na cadeia RAG!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3970723560.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm_for_chain = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "print(\"Construindo a cadeia RAG...\")\n",
        "\n",
        "# --- 1. Definir o Retriever a partir do nosso Vector Store ---\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) # k=3 significa que buscarÃ¡ os 3 chunks mais relevantes\n",
        "# --- 2. Criar o Template do Prompt ---\n",
        "\n",
        "template = \"\"\"\n",
        "VocÃª Ã© um assistente jurÃ­dico no Brasil. Use APENAS o contexto a seguir para responder Ã  pergunta.\n",
        "Se a resposta nÃ£o estiver no contexto, diga \"Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\"\n",
        "Cite a fonte do documento de onde extraiu a resposta.\n",
        "\n",
        "Contexto: {context}\n",
        "\n",
        "Pergunta: {question}\n",
        "\n",
        "---\n",
        "ApÃ³s a resposta, adicione em uma nova linha sua confianÃ§a na resposta de 0 a 100% no formato \"ConfianÃ§a: XX%\". A confianÃ§a deve ser alta se o contexto responde diretamente Ã  pergunta.\n",
        "\n",
        "Resposta:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# --- 3. FunÃ§Ã£o para formatar os documentos recuperados ---\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(f\"Fonte: {doc.metadata.get('source', 'N/A')}\\n{doc.page_content}\" for doc in docs)\n",
        "\n",
        "# --- 4. Montar a Cadeia (Chain) ---\n",
        "# Esta Ã© a sequÃªncia de passos que o sistema executarÃ¡\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm_for_chain\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"âœ… Cadeia RAG montada e pronta para uso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwZoIMPtKxAi",
        "outputId": "7df13b5f-8937-422c-fc60-3775c2a121b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construindo a cadeia RAG...\n",
            "âœ… Cadeia RAG montada e pronta para uso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FaÃ§a uma pergunta relacionada aos PDFs que vocÃª subiu\n",
        "query = \"De acordo com o CÃ³digo de Defesa do Consumidor, qual Ã© o prazo para reclamar de vÃ­cios aparentes em produtos nÃ£o durÃ¡veis e em produtos durÃ¡veis?\"\n",
        "\n",
        "print(f\"Enviando a pergunta: '{query}'\")\n",
        "print(\"\\nAguardando a resposta do sistema RAG...\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# O mÃ©todo .invoke() executa a cadeia completa\n",
        "response = rag_chain.invoke(query)\n",
        "\n",
        "# Imprime a resposta final\n",
        "print(response)\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFq6i2YFK1hX",
        "outputId": "3011bb3d-3a38-4d24-becf-0adf57904502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enviando a pergunta: 'De acordo com o CÃ³digo de Defesa do Consumidor, qual Ã© o prazo para reclamar de vÃ­cios aparentes em produtos nÃ£o durÃ¡veis e em produtos durÃ¡veis?'\n",
            "\n",
            "Aguardando a resposta do sistema RAG...\n",
            "==============================\n",
            "\n",
            "VocÃª Ã© um assistente jurÃ­dico no Brasil. Use APENAS o contexto a seguir para responder Ã  pergunta.\n",
            "Se a resposta nÃ£o estiver no contexto, diga \"Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\"\n",
            "Cite a fonte do documento se possÃ­vel.\n",
            "\n",
            "Contexto: Fonte: Consumidor.pdf\n",
            "Â§ 3Â° O fornecedor de serviÃ§os sÃ³ nÃ£o serÃ¡ responsabilizado quando provar:\n",
            "I - que, tendo prestado o serviÃ§o, o defeito inexiste;\n",
            "II - a culpa exclusiva do consumidor ou de terceiro.\n",
            "Â§ 4Â° A responsabilidade pessoal dos profissionais liberais serÃ¡ apurada mediante a verificaÃ§Ã£o de culpa.\n",
            "Art. 15. (Vetado).\n",
            "Art. 16. (Vetado).\n",
            "Art. 17. Para os efeitos desta SeÃ§Ã£o, equiparam-se aos consumidores todas as vÃ­timas do evento.\n",
            "Da Responsabilidade por VÃ­cio do Produto e do ServiÃ§o\n",
            "Art. 18. Os fornecedores de produtos de consumo durÃ¡veis ou nÃ£o durÃ¡veis respondem solidariamente pelos vÃ­cios\n",
            "de qualidade ou quantidade que os tornem imprÃ³prios ou inadequados ao consumo a que se destinam ou lhes diminuam\n",
            "o valor, assim como por aqueles decorrentes da disparidade, com a indicaÃ§Ãµes constantes do recipiente, da embalagem,\n",
            "rotulagem ou mensagem publicitÃ¡ria, respeitadas as variaÃ§Ãµes decorrentes de sua natureza, podendo o consumidor\n",
            "exigir a substituiÃ§Ã£o das partes viciadas.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Â§ 5Â° No caso de fornecimento de produtos in natura, serÃ¡ responsÃ¡vel perante o consumidor o fornecedor imediato,\n",
            "exceto quando identificado claramente seu produtor.\n",
            "Â§ 6Â° SÃ£o imprÃ³prios ao uso e consumo:\n",
            "I - os produtos cujos prazos de validade estejam vencidos;\n",
            "II - os produtos deteriorados, alterados, adulterados, avariados, falsificados, corrompidos, fraudados, nocivos Ã  vida\n",
            "ou Ã  saÃºde, perigosos ou, ainda, aqueles em desacordo com as normas regulamentares de fabricaÃ§Ã£o, distribuiÃ§Ã£o ou\n",
            "apresentaÃ§Ã£o;\n",
            "III - os produtos que, por qualquer motivo, se revelem inadequados ao fim a que se destinam.\n",
            "Art. 19. Os fornecedores respondem solidariamente pelos vÃ­cios de quantidade do produto sempre que, respeitadas\n",
            "as variaÃ§Ãµes decorrentes de sua natureza, seu conteÃºdo lÃ­quido for inferior Ã s indicaÃ§Ãµes constantes do recipiente, da\n",
            "embalagem, rotulagem ou de mensagem publicitÃ¡ria, podendo o consumidor exigir, alternativamente e Ã  sua escolha:\n",
            "I - o abatimento proporcional do preÃ§o;\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "implÃ­cita a obrigaÃ§Ã£o do fornecedor de empregar componentes de reposiÃ§Ã£o originais adequados e novos, ou que\n",
            "mantenham as especificaÃ§Ãµes tÃ©cnicas do fabricante, salvo, quanto a estes Ãºltimos, autorizaÃ§Ã£o em contrÃ¡rio do\n",
            "consumidor.\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm 5/23\n",
            "30/09/2025, 10:33 L8078compilado\n",
            "Art. 22. Os Ã³rgÃ£os pÃºblicos, por si ou suas empresas, concessionÃ¡rias, permissionÃ¡rias ou sob qualquer outra forma\n",
            "de empreendimento, sÃ£o obrigados a fornecer serviÃ§os adequados, eficientes, seguros e, quanto aos essenciais,\n",
            "ParÃ¡grafo Ãºnico. Nos casos de descumprimento, total ou parcial, das obrigaÃ§Ãµes referidas neste artigo, serÃ£o as\n",
            "pessoas jurÃ­dicas compelidas a cumpri-las e a reparar os danos causados, na forma prevista neste cÃ³digo.\n",
            "Art. 23. A ignorÃ¢ncia do fornecedor sobre os vÃ­cios de qualidade por inadequaÃ§Ã£o dos produtos e serviÃ§os nÃ£o o\n",
            "exime de responsabilidade.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "comunicaÃ§Ã£o com relaÃ§Ã£o a produtos e serviÃ§os oferecidos ou apresentados, obriga o fornecedor que a fizer veicular ou\n",
            "dela se utilizar e integra o contrato que vier a ser celebrado.\n",
            "Art. 31. A oferta e apresentaÃ§Ã£o de produtos ou serviÃ§os devem assegurar informaÃ§Ãµes corretas, claras, precisas,\n",
            "ostensivas e em lÃ­ngua portuguesa sobre suas caracterÃ­sticas, qualidades, quantidade, composiÃ§Ã£o, preÃ§o, garantia,\n",
            "prazos de validade e origem, entre outros dados, bem como sobre os riscos que apresentam Ã  saÃºde e seguranÃ§a dos\n",
            "consumidores.\n",
            "ParÃ¡grafo Ãºnico. As informaÃ§Ãµes de que trata este artigo, nos produtos refrigerados oferecidos ao consumidor,\n",
            "serÃ£o gravadas de forma indelÃ©vel. (IncluÃ­do pela Lei nÂº 11.989, de 2009)\n",
            "Art. 32. Os fabricantes e importadores deverÃ£o assegurar a oferta de componentes e peÃ§as de reposiÃ§Ã£o enquanto\n",
            "nÃ£o cessar a fabricaÃ§Ã£o ou importaÃ§Ã£o do produto.\n",
            "ParÃ¡grafo Ãºnico. Cessadas a produÃ§Ã£o ou importaÃ§Ã£o, a oferta deverÃ¡ ser mantida por perÃ­odo razoÃ¡vel de tempo,\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 23. A ignorÃ¢ncia do fornecedor sobre os vÃ­cios de qualidade por inadequaÃ§Ã£o dos produtos e serviÃ§os nÃ£o o\n",
            "exime de responsabilidade.\n",
            "Art. 24. A garantia legal de adequaÃ§Ã£o do produto ou serviÃ§o independe de termo expresso, vedada a exoneraÃ§Ã£o\n",
            "contratual do fornecedor.\n",
            "Art. 25. Ã‰ vedada a estipulaÃ§Ã£o contratual de clÃ¡usula que impossibilite, exonere ou atenue a obrigaÃ§Ã£o de indenizar\n",
            "prevista nesta e nas seÃ§Ãµes anteriores.\n",
            "Â§ 1Â° Havendo mais de um responsÃ¡vel pela causaÃ§Ã£o do dano, todos responderÃ£o solidariamente pela reparaÃ§Ã£o\n",
            "prevista nesta e nas seÃ§Ãµes anteriores.\n",
            "Â§ 2Â° Sendo o dano causado por componente ou peÃ§a incorporada ao produto ou serviÃ§o, sÃ£o responsÃ¡veis\n",
            "solidÃ¡rios seu fabricante, construtor ou importador e o que realizou a incorporaÃ§Ã£o.\n",
            "Da DecadÃªncia e da PrescriÃ§Ã£o\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "\n",
            "Pergunta: De acordo com o CÃ³digo de Defesa do Consumidor, qual Ã© o prazo para reclamar de vÃ­cios aparentes em produtos nÃ£o durÃ¡veis e em produtos durÃ¡veis?\n",
            "\n",
            "Resposta:\n",
            "Com base nos documentos fornecidos, o prazo para reclamar de vÃ­cios aparentes em produtos nÃ£o durÃ¡veis Ã© de 30 dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis. (Art. 26, I, Fonte: Consumidor.pdf) 30/09/2025, 10:33 L8078compilado\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "II - noventa dias, tratando-se de produtos durÃ¡veis.\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 27. O direito de reclamar pelos vÃ­cios nÃ£o aparentes ou de difÃ­cil constataÃ§Ã£o caduca em:\n",
            "I - cento e oitenta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - dois anos, tratando-se de produtos durÃ¡veis.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 28. O prazo de decadÃªncia e prescriÃ§Ã£o comeÃ§arÃ¡ a correr a partir da data do conhecimento do consumidor\n",
            "dos vÃ­cios ou da data do tÃ©rmino do prazo de validade, se for aplicÃ¡vel.\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 29. O consumidor tem direito a reclamar do fornecedor, dentro do prazo de decadÃªncia, a reparaÃ§Ã£o dos danos\n",
            "causados, desde que o vÃ­cio seja aparente ou nÃ£o aparente, e a exigir a substituiÃ§Ã£o das partes viciadas.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 30. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 31. A oferta e apresentaÃ§Ã£o de produtos ou serviÃ§os devem assegurar informaÃ§Ãµes corretas, claras, precisas, ostensivas\n",
            "e em lÃ­ngua portuguesa sobre suas caracterÃ­sticas, qualidades, quantidade, composiÃ§Ã£o, preÃ§o, garantia, prazos de validade\n",
            "e origem, entre outros dados, bem como sobre os riscos que apresentam Ã  saÃºde e seguranÃ§a dos consumidores.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 32. Os fabricantes e importadores deverÃ£o assegurar a oferta de componentes e peÃ§as de reposiÃ§Ã£o enquanto\n",
            "nÃ£o cessar a fabricaÃ§Ã£o ou importaÃ§Ã£o do produto.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 33. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 34. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 35. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 36. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 37. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 38. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 39. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 40. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 41. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 42. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o eletrÃ´nica.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 43. A reclamaÃ§Ã£o do consumidor pode ser feita por escrito, verbalmente ou por meio de comunicaÃ§Ã£o\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Definindo a funÃ§Ã£o de classificaÃ§Ã£o...\")\n",
        "\n",
        "# Prompt para instruir o LLM a agir como um classificador\n",
        "CLASSIFIER_PROMPT = \"\"\"\n",
        "Sua Ãºnica tarefa Ã© classificar a pergunta do usuÃ¡rio em uma das 4 categorias abaixo. Retorne APENAS o nome da categoria.\n",
        "\n",
        "Categorias:\n",
        "1.  'rag_required': A pergunta exige conhecimento de leis, artigos, cÃ³digos ou jurisprudÃªncia.\n",
        "2.  'calculation_required': A pergunta pede um cÃ¡lculo numÃ©rico baseado em regras jurÃ­dicas.\n",
        "3.  'general_conversation': Ã‰ uma saudaÃ§Ã£o, agradecimento ou conversa casual.\n",
        "4.  'out_of_scope': A pergunta nÃ£o tem relaÃ§Ã£o com o domÃ­nio jurÃ­dico.\n",
        "\n",
        "Pergunta do UsuÃ¡rio: \"{user_query}\"\n",
        "\n",
        "Categoria:\n",
        "\"\"\"\n",
        "\n",
        "# Criamos uma cadeia especÃ­fica para a classificaÃ§Ã£o\n",
        "classifier_chain = (\n",
        "    PromptTemplate.from_template(CLASSIFIER_PROMPT)\n",
        "    | llm_for_chain # Usamos o mesmo LLM jÃ¡ preparado\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "def classify_query(user_query: str) -> str:\n",
        "    \"\"\"Classifica a query do usuÃ¡rio em uma das 4 categorias.\"\"\"\n",
        "    response = classifier_chain.invoke({\"user_query\": user_query})\n",
        "    # Limpeza para garantir que apenas o nome da categoria seja retornado\n",
        "    clean_response = response.strip().lower()\n",
        "\n",
        "    valid_categories = [\"rag_required\", \"calculation_required\", \"general_conversation\", \"out_of_scope\"]\n",
        "    for category in valid_categories:\n",
        "        if category in clean_response:\n",
        "            print(f\"Query classificada como: '{category}'\")\n",
        "            return category\n",
        "\n",
        "    print(\"ClassificaÃ§Ã£o nÃ£o foi clara, retornando 'out_of_scope'.\")\n",
        "    return \"out_of_scope\" # Fallback seguro\n",
        "\n",
        "print(\"âœ… FunÃ§Ã£o 'classify_query' pronta.\")\n",
        "\n",
        "# Teste rÃ¡pido (opcional)\n",
        "# classify_query(\"OlÃ¡, tudo bem?\")\n",
        "# classify_query(\"Como calculo minhas fÃ©rias?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZAJdBgwK2Bb",
        "outputId": "4dccff36-36be-4c16-fc1d-1e28ad58b96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definindo a funÃ§Ã£o de classificaÃ§Ã£o...\n",
            "âœ… FunÃ§Ã£o 'classify_query' pronta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# --- Disclaimers (Avisos Legais) ---\n",
        "DISCLAIMER_RAG = \"\\n\\n---\\n*AVISO: Esta resposta foi gerada por IA e nÃ£o substitui a consulta a um profissional do Direito. Verifique as fontes.*\"\n",
        "DISCLAIMER_GENERAL = \"\\n\\n---\\n*AVISO: Esta Ã© uma resposta conversacional e nÃ£o deve ser interpretada como aconselhamento jurÃ­dico.*\"\n",
        "\n",
        "# --- A FunÃ§Ã£o Mestra ---\n",
        "def chatbot_response(message, history):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o principal que o Gradio irÃ¡ chamar.\n",
        "    Orquestra a classificaÃ§Ã£o e a geraÃ§Ã£o da resposta.\n",
        "    \"\"\"\n",
        "    # 1. Classifica a pergunta\n",
        "    classification = classify_query(message)\n",
        "\n",
        "    # 2. Age com base na classificaÃ§Ã£o\n",
        "    if classification == 'rag_required' or classification == 'calculation_required':\n",
        "        # Se for RAG, chama a cadeia RAG que jÃ¡ testamos\n",
        "        response = rag_chain.invoke(message)\n",
        "        final_response = response.strip() + DISCLAIMER_RAG\n",
        "\n",
        "    elif classification == 'general_conversation':\n",
        "        # Se for conversa, usa o LLM com um prompt simples\n",
        "        general_prompt = f\"VocÃª Ã© um assistente virtual. Responda Ã  seguinte mensagem de forma breve e amigÃ¡vel: '{message}'\"\n",
        "        response = llm_for_chain.invoke(general_prompt)\n",
        "        final_response = response.strip() + DISCLAIMER_GENERAL\n",
        "\n",
        "    else: # out_of_scope\n",
        "        # Se for fora de escopo, retorna uma mensagem padrÃ£o\n",
        "        final_response = \"Desculpe, meu conhecimento Ã© focado em legislaÃ§Ã£o brasileira. NÃ£o consigo ajudar com este tÃ³pico.\"\n",
        "\n",
        "    return final_response\n",
        "\n",
        "# --- 3. Inicia a Interface Gradio ---\n",
        "print(\"\\nIniciando a interface do Chatbot JurÃ­dico...\")\n",
        "\n",
        "gr.ChatInterface(\n",
        "    fn=chatbot_response,\n",
        "    title=\"âš–ï¸ Chatbot JurÃ­dico Inteligente (Local)\",\n",
        "    description=\"FaÃ§a uma pergunta sobre a CLT, CÃ³digo de Defesa do Consumidor ou CÃ³digo Civil com base nos arquivos carregados.\",\n",
        "    examples=[\n",
        "        \"Qual o prazo para reclamar de vÃ­cios em produtos durÃ¡veis?\",\n",
        "        \"Como funciona a jornada de trabalho de 12 por 36 horas?\",\n",
        "        \"O que Ã© considerado uniÃ£o estÃ¡vel?\",\n",
        "        \"OlÃ¡, qual seu nome?\"\n",
        "    ],\n",
        "    cache_examples=False\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "SzY5HNfnRH7V",
        "outputId": "951c5497-5b35-4f71-ef16-69f98732742f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iniciando a interface do Chatbot JurÃ­dico...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:348: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://db7804d9983044d510.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://db7804d9983044d510.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://db7804d9983044d510.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"ðŸ“Š Iniciando a avaliaÃ§Ã£o do classificador...\")\n",
        "\n",
        "# Amostra do Dataset de Teste de ClassificaÃ§Ã£o\n",
        "classification_test_set = {\n",
        "    \"rag_required\": [\n",
        "        \"o que a clt fala sobre fÃ©rias?\",\n",
        "        \"qual a puniÃ§Ã£o para o crime de roubo segundo o cÃ³digo penal?\",\n",
        "        \"tenho direito a danos morais por cobranÃ§a indevida?\",\n",
        "        \"como funciona a usucapiÃ£o de um imÃ³vel?\",\n",
        "    ],\n",
        "    \"calculation_required\": [\n",
        "        \"como calculo minha rescisÃ£o com aviso prÃ©vio?\",\n",
        "        \"qual o valor da multa de 40% do FGTS para um saldo de R$ 12.000?\",\n",
        "        \"qual o valor de 1/3 de fÃ©rias sobre um salÃ¡rio de 3000 reais?\",\n",
        "    ],\n",
        "    \"general_conversation\": [\n",
        "        \"oi tudo bem?\",\n",
        "        \"muito obrigado pela ajuda\",\n",
        "        \"quem te criou?\",\n",
        "        \"vocÃª Ã© um robÃ´?\",\n",
        "    ],\n",
        "    \"out_of_scope\": [\n",
        "        \"qual a previsÃ£o do tempo para amanhÃ£?\",\n",
        "        \"me conte uma piada\",\n",
        "        \"qual o melhor time de futebol do brasil?\",\n",
        "        \"receita de bolo de cenoura\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Executa a classificaÃ§Ã£o para cada item do dataset\n",
        "for label, queries in classification_test_set.items():\n",
        "    for query in queries:\n",
        "        true_labels.append(label)\n",
        "        predicted_category = classify_query(query)\n",
        "        predicted_labels.append(predicted_category)\n",
        "\n",
        "# Gera o relatÃ³rio de classificaÃ§Ã£o\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RelatÃ³rio de Performance do Classificador\")\n",
        "print(\"=\"*50)\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)\n",
        "print(\"=\"*50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "GIdz3Z6iasZ2",
        "outputId": "7b337463-5b8b-4079-dc64-f8c7e9e2ca11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Iniciando a avaliaÃ§Ã£o do classificador...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query classificada como: 'rag_required'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3950136370.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mpredicted_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2147021889.py\u001b[0m in \u001b[0;36mclassify_query\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\"Classifica a query do usuÃ¡rio em uma das 4 categorias.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"user_query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Limpeza para garantir que apenas o nome da categoria seja retornado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mclean_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3245\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3246\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    788\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 )\n\u001b[1;32m    999\u001b[0m             ]\n\u001b[0;32m-> 1000\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m   1001\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             output = (\n\u001b[0;32m--> 815\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    816\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                 )\n\u001b[0;32m-> 1448\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m             \u001b[0;31m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2540\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2868\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2870\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                         \u001b[0mmonkey_patched_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;31m# Restore original forward methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_forward\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonkey_patched_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nltk"
      ],
      "metadata": {
        "id": "24knI2XMfb_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "print(\"\\n\\nðŸ“Š Iniciando a avaliaÃ§Ã£o do Sistema RAG...\")\n",
        "\n",
        "# Amostra do Dataset de Teste RAG com perguntas e respostas de referÃªncia\n",
        "rag_test_set = [\n",
        "    {\n",
        "        \"question\": \"Qual o prazo para reclamar de vÃ­cios em produtos durÃ¡veis?\",\n",
        "        \"reference_answer\": \"O direito de reclamar por vÃ­cios aparentes em produtos durÃ¡veis caduca em noventa dias.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"AtÃ© quantas horas extras por dia um funcionÃ¡rio pode fazer segundo a CLT?\",\n",
        "        \"reference_answer\": \"A duraÃ§Ã£o diÃ¡ria do trabalho poderÃ¡ ser acrescida de horas extras, em nÃºmero nÃ£o excedente de duas.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"O que acontece se eu me demitir sem justa causa antes do fim do contrato com prazo determinado?\",\n",
        "        \"reference_answer\": \"Havendo termo estipulado, o empregado nÃ£o se poderÃ¡ desligar do contrato, sem justa causa, sob pena de ser obrigado a indenizar o empregador dos prejuÃ­zos que desse fato lhe resultarem.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "total_bleu_score = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Avaliando Respostas do RAG\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for item in rag_test_set:\n",
        "    question = item[\"question\"]\n",
        "    reference = item[\"reference_answer\"].split() # A resposta de referÃªncia como lista de palavras\n",
        "\n",
        "    # Gera a resposta com nosso sistema RAG\n",
        "    generated_answer = rag_chain.invoke(question)\n",
        "    generated = generated_answer.split() # A resposta gerada como lista de palavras\n",
        "\n",
        "    # Calcula o score BLEU\n",
        "    bleu_score = sentence_bleu([reference], generated, weights=(0.5, 0.5)) # Usando bi-grams\n",
        "    total_bleu_score += bleu_score\n",
        "\n",
        "    print(f\"Pergunta: {question}\")\n",
        "    print(f\"  -> Resposta Esperada: {item['reference_answer']}\")\n",
        "    print(f\"  -> Resposta Gerada: {generated_answer.strip()}\")\n",
        "    print(f\"  -> Score BLEU: {bleu_score:.4f}\")\n",
        "    print(\"-\"*20)\n",
        "\n",
        "avg_bleu = total_bleu_score / len(rag_test_set)\n",
        "print(f\"\\nScore BLEU MÃ©dio: {avg_bleu:.4f}\")\n",
        "print(\"=\"*50)\n",
        "# Um score acima de 0.5-0.6 jÃ¡ Ã© considerado muito bom. Guarde este resultado."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Thokz3_fipO",
        "outputId": "af643c3e-5429-4523-ab9c-0897f03bddb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ðŸ“Š Iniciando a avaliaÃ§Ã£o do Sistema RAG...\n",
            "\n",
            "==================================================\n",
            "Avaliando Respostas do RAG\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Qual o prazo para reclamar de vÃ­cios em produtos durÃ¡veis?\n",
            "  -> Resposta Esperada: O direito de reclamar por vÃ­cios aparentes em produtos durÃ¡veis caduca em noventa dias.\n",
            "  -> Resposta Gerada: VocÃª Ã© um assistente jurÃ­dico no Brasil. Use APENAS o contexto a seguir para responder Ã  pergunta.\n",
            "Se a resposta nÃ£o estiver no contexto, diga \"Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\"\n",
            "Cite a fonte do documento de onde extraiu a resposta.\n",
            "\n",
            "Contexto: Fonte: Consumidor.pdf\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - noventa dias, tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis.\n",
            "Â§ 1Â° Inicia-se a contagem do prazo decadencial a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o\n",
            "dos serviÃ§os.\n",
            "Â§ 2Â° Obstam a decadÃªncia:\n",
            "I - a reclamaÃ§Ã£o comprovadamente formulada pelo consumidor perante o fornecedor de produtos e serviÃ§os atÃ© a\n",
            "resposta negativa correspondente, que deve ser transmitida de forma inequÃ­voca;\n",
            "II - (Vetado).\n",
            "III - a instauraÃ§Ã£o de inquÃ©rito civil, atÃ© seu encerramento.\n",
            "Â§ 3Â° Tratando-se de vÃ­cio oculto, o prazo decadencial inicia-se no momento em que ficar evidenciado o defeito.\n",
            "Art. 27. Prescreve em cinco anos a pretensÃ£o Ã  reparaÃ§Ã£o pelos danos causados por fato do produto ou do serviÃ§o\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Â§ 5Â° No caso de fornecimento de produtos in natura, serÃ¡ responsÃ¡vel perante o consumidor o fornecedor imediato,\n",
            "exceto quando identificado claramente seu produtor.\n",
            "Â§ 6Â° SÃ£o imprÃ³prios ao uso e consumo:\n",
            "I - os produtos cujos prazos de validade estejam vencidos;\n",
            "II - os produtos deteriorados, alterados, adulterados, avariados, falsificados, corrompidos, fraudados, nocivos Ã  vida\n",
            "ou Ã  saÃºde, perigosos ou, ainda, aqueles em desacordo com as normas regulamentares de fabricaÃ§Ã£o, distribuiÃ§Ã£o ou\n",
            "apresentaÃ§Ã£o;\n",
            "III - os produtos que, por qualquer motivo, se revelem inadequados ao fim a que se destinam.\n",
            "Art. 19. Os fornecedores respondem solidariamente pelos vÃ­cios de quantidade do produto sempre que, respeitadas\n",
            "as variaÃ§Ãµes decorrentes de sua natureza, seu conteÃºdo lÃ­quido for inferior Ã s indicaÃ§Ãµes constantes do recipiente, da\n",
            "embalagem, rotulagem ou de mensagem publicitÃ¡ria, podendo o consumidor exigir, alternativamente e Ã  sua escolha:\n",
            "I - o abatimento proporcional do preÃ§o;\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Â§ 3Â° O fornecedor de serviÃ§os sÃ³ nÃ£o serÃ¡ responsabilizado quando provar:\n",
            "I - que, tendo prestado o serviÃ§o, o defeito inexiste;\n",
            "II - a culpa exclusiva do consumidor ou de terceiro.\n",
            "Â§ 4Â° A responsabilidade pessoal dos profissionais liberais serÃ¡ apurada mediante a verificaÃ§Ã£o de culpa.\n",
            "Art. 15. (Vetado).\n",
            "Art. 16. (Vetado).\n",
            "Art. 17. Para os efeitos desta SeÃ§Ã£o, equiparam-se aos consumidores todas as vÃ­timas do evento.\n",
            "Da Responsabilidade por VÃ­cio do Produto e do ServiÃ§o\n",
            "Art. 18. Os fornecedores de produtos de consumo durÃ¡veis ou nÃ£o durÃ¡veis respondem solidariamente pelos vÃ­cios\n",
            "de qualidade ou quantidade que os tornem imprÃ³prios ou inadequados ao consumo a que se destinam ou lhes diminuam\n",
            "o valor, assim como por aqueles decorrentes da disparidade, com a indicaÃ§Ãµes constantes do recipiente, da embalagem,\n",
            "rotulagem ou mensagem publicitÃ¡ria, respeitadas as variaÃ§Ãµes decorrentes de sua natureza, podendo o consumidor\n",
            "exigir a substituiÃ§Ã£o das partes viciadas.\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 23. A ignorÃ¢ncia do fornecedor sobre os vÃ­cios de qualidade por inadequaÃ§Ã£o dos produtos e serviÃ§os nÃ£o o\n",
            "exime de responsabilidade.\n",
            "Art. 24. A garantia legal de adequaÃ§Ã£o do produto ou serviÃ§o independe de termo expresso, vedada a exoneraÃ§Ã£o\n",
            "contratual do fornecedor.\n",
            "Art. 25. Ã‰ vedada a estipulaÃ§Ã£o contratual de clÃ¡usula que impossibilite, exonere ou atenue a obrigaÃ§Ã£o de indenizar\n",
            "prevista nesta e nas seÃ§Ãµes anteriores.\n",
            "Â§ 1Â° Havendo mais de um responsÃ¡vel pela causaÃ§Ã£o do dano, todos responderÃ£o solidariamente pela reparaÃ§Ã£o\n",
            "prevista nesta e nas seÃ§Ãµes anteriores.\n",
            "Â§ 2Â° Sendo o dano causado por componente ou peÃ§a incorporada ao produto ou serviÃ§o, sÃ£o responsÃ¡veis\n",
            "solidÃ¡rios seu fabricante, construtor ou importador e o que realizou a incorporaÃ§Ã£o.\n",
            "Da DecadÃªncia e da PrescriÃ§Ã£o\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "\n",
            "Fonte: Consumidor.pdf\n",
            "implÃ­cita a obrigaÃ§Ã£o do fornecedor de empregar componentes de reposiÃ§Ã£o originais adequados e novos, ou que\n",
            "mantenham as especificaÃ§Ãµes tÃ©cnicas do fabricante, salvo, quanto a estes Ãºltimos, autorizaÃ§Ã£o em contrÃ¡rio do\n",
            "consumidor.\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm 5/23\n",
            "30/09/2025, 10:33 L8078compilado\n",
            "Art. 22. Os Ã³rgÃ£os pÃºblicos, por si ou suas empresas, concessionÃ¡rias, permissionÃ¡rias ou sob qualquer outra forma\n",
            "de empreendimento, sÃ£o obrigados a fornecer serviÃ§os adequados, eficientes, seguros e, quanto aos essenciais,\n",
            "ParÃ¡grafo Ãºnico. Nos casos de descumprimento, total ou parcial, das obrigaÃ§Ãµes referidas neste artigo, serÃ£o as\n",
            "pessoas jurÃ­dicas compelidas a cumpri-las e a reparar os danos causados, na forma prevista neste cÃ³digo.\n",
            "Art. 23. A ignorÃ¢ncia do fornecedor sobre os vÃ­cios de qualidade por inadequaÃ§Ã£o dos produtos e serviÃ§os nÃ£o o\n",
            "exime de responsabilidade.\n",
            "\n",
            "Pergunta: Qual o prazo para reclamar de vÃ­cios em produtos durÃ¡veis?\n",
            "\n",
            "---\n",
            "ApÃ³s a resposta, adicione em uma nova linha sua confianÃ§a na resposta de 0 a 100% no formato \"ConfianÃ§a: XX%\". A confianÃ§a deve ser alta se o contexto responde diretamente Ã  pergunta.\n",
            "\n",
            "Resposta:\n",
            "Tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis, o prazo decadencial Ã© de noventa dias, a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o dos serviÃ§os.\n",
            "\n",
            "ConfianÃ§a: 100%\n",
            "Fonte: Art. 26, Consumidor.pdf\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm\n",
            "L8078compilado\n",
            "5/23\n",
            "30/09/2025, 10:33\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - noventa dias, tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis.\n",
            "Â§ 1Â° Inicia-se a contagem do prazo decadencial a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o dos serviÃ§os.\n",
            "Â§ 2Â° Obstam a decadÃªncia:\n",
            "I - a reclamaÃ§Ã£o comprovadamente formulada pelo consumidor perante o fornecedor de produtos e serviÃ§os atÃ© a resposta\n",
            "negativa correspondente, que deve ser transmitida de forma inequÃ­voca;\n",
            "II - (Vetado).\n",
            "III - a instauraÃ§Ã£o de inquÃ©rito civil, atÃ© seu encerramento.\n",
            "Â§ 3Â° Tratando-se de vÃ­cio oculto, o prazo decadencial inicia-se no momento em que ficar evidenciado o defeito. Fonte: Consumidor.pdf\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm\n",
            "L8078compilado\n",
            "5/23\n",
            "30/09/2025, 10:33\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - noventa dias, tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis.\n",
            "Â§ 1Â° Inicia-se a contagem do prazo decadencial a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o dos serviÃ§os.\n",
            "Â§ 2Â° Obstam a decadÃªncia:\n",
            "I - a reclamaÃ§Ã£o comprovadamente formulada pelo consumidor perante o fornecedor de produtos e serviÃ§os atÃ© a resposta\n",
            "negativa correspondente, que deve ser transmitida de forma inequÃ­voca;\n",
            "II - (Vetado).\n",
            "III - a instauraÃ§Ã£o de inquÃ©rito civil, atÃ© seu encerramento.\n",
            "Â§ 3Â° Tratando-se de vÃ­cio oculto, o prazo decadencial inicia-se no momento em que ficar evidenciado o defeito. Fonte: Consumidor.pdf\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm\n",
            "L8078compilado\n",
            "5/23\n",
            "30/09/2025, 10:33\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - noventa dias, tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis.\n",
            "Â§ 1Â° Inicia-se a contagem do prazo decadencial a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o dos serviÃ§os.\n",
            "Â§ 2Â° Obstam a decadÃªncia:\n",
            "I - a reclamaÃ§Ã£o comprovadamente formulada pelo consumidor perante o fornecedor de produtos e serviÃ§os atÃ© a resposta\n",
            "negativa correspondente, que deve ser transmitida de forma inequÃ­voca;\n",
            "II - (Vetado).\n",
            "III - a instauraÃ§Ã£o de inquÃ©rito civil, atÃ© seu encerramento.\n",
            "Â§ 3Â° Tratando-se de vÃ­cio oculto, o prazo decadencial inicia-se no momento em que ficar evidenciado o defeito. Fonte: Consumidor.pdf\n",
            "https://www.planalto.gov.br/ccivil_03/leis/l8078compilado.htm\n",
            "L8078compilado\n",
            "5/23\n",
            "30/09/2025, 10:33\n",
            "Fonte: Consumidor.pdf\n",
            "Art. 26. O direito de reclamar pelos vÃ­cios aparentes ou de fÃ¡cil constataÃ§Ã£o caduca em:\n",
            "I - trinta dias, tratando-se de fornecimento de serviÃ§o e de produtos nÃ£o durÃ¡veis;\n",
            "II - noventa dias, tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis\n",
            "  -> Score BLEU: 0.0068\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: AtÃ© quantas horas extras por dia um funcionÃ¡rio pode fazer segundo a CLT?\n",
            "  -> Resposta Esperada: A duraÃ§Ã£o diÃ¡ria do trabalho poderÃ¡ ser acrescida de horas extras, em nÃºmero nÃ£o excedente de duas.\n",
            "  -> Resposta Gerada: VocÃª Ã© um assistente jurÃ­dico no Brasil. Use APENAS o contexto a seguir para responder Ã  pergunta.\n",
            "Se a resposta nÃ£o estiver no contexto, diga \"Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\"\n",
            "Cite a fonte do documento de onde extraiu a resposta.\n",
            "\n",
            "Contexto: Fonte: trabalhista.pdf\n",
            "homens e mulheres, em particular as que se destinam a corrigir as distorÃ§Ãµes que afetam a formaÃ§Ã£o profissional, o acesso ao emprego e as condiÃ§Ãµes\n",
            "gerais de trabalho da mulher. (IncluÃ­do pela Lei nÂº 9.799, de 26.5.1999)\n",
            "Art. 374. A duraÃ§Ã£o normal do trabalho diurno da mulher poderÃ¡ ser no mÃ¡ximo elevada de mais duas horas, mediante contrato coletivo ou acordo\n",
            "firmado entre empregados e empregadores, observado o limite de quarenta e oito horas semanais.\n",
            "ParÃ¡grafo Ãºnico. O acordo ou contrato coletivo de trabalho deverÃ¡ ser homologado pela autoridade competente e do mesmo constarÃ¡,\n",
            "obrigatoriamente, a importÃ¢ncia do salÃ¡rio da hora suplementar, que serÃ¡ igual a da hora normal acrescida de uma percentagem adicional de 20 % (vinte\n",
            "por cento) no mÃ­nimo.\n",
            "ïƒ£ Art. 374 - A duraÃ§Ã£o normal diÃ¡ria do trabalho da mulher poderÃ¡ ser no mÃ¡ximo elevada de 2 (duas) horas, independentemente de\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "da responsabilidade de terceiros, os operÃ¡rios escalados perceberÃ£o o tempo que ficarem paralisados, na base dos salÃ¡rios vigentes, cabendo Ã s\n",
            "administraÃ§Ãµes dos portos, se nÃ£o forem elas as responsÃ¡veis, o direito de cobrar a quantia paga pela inatividade Ã  entidade que motivar a paralisaÃ§Ã£o.\n",
            "Â§ 4Âº Quando a quantidade de mercadorias a manipular por uma turma for tÃ£o pequena que nÃ£o assegure, para cada um dos operÃ¡rios e\n",
            "empregados escalados, o provento do meio dia de salÃ¡rio, ao menos, os operÃ¡rios e empregados perceberÃ£o a remuneraÃ§Ã£o correspondente ao meio dia\n",
            "de salÃ¡rio vigente.\n",
            "Â§ 5Âº Se o trabalho a que se refere o parÃ¡grafo anterior exceder em duraÃ§Ã£o a meio dia de trabalho e, em quantidade, a 30 toneladas, os operÃ¡rios\n",
            "perceberÃ£o a remuneraÃ§Ã£o por salÃ¡rio, correspondente ao nÃºmero de horas da efetiva duraÃ§Ã£o do serviÃ§o.\n",
            "Â§ 6Âº Os operÃ¡rios mensalistas e os diaristas que, Ã  data do decreto-lei nÂº 3.844, de 20 de novembro de 1941, tinham direito a determinada\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "turma empregada na execuÃ§Ã£o do serviÃ§o, distinguidos os casos de trabalhar um ou mais guindastes, por porÃ£o de navio, ou uma ou mais portas de\n",
            "ParÃ¡grafo Ãºnico. Quando condiÃ§Ãµes especias do serviÃ§o exigirem o aumento do nÃºmero de trabalhadores fixados para compor as turmas, este\n",
            "aumento serÃ¡ feito, a critÃ©rio das administraÃ§Ãµes dos portos, e a sua remuneraÃ§Ã£o serÃ¡ idÃªntica Ã  que couber aos trabalhadores componentes normais\n",
            "das turmas. (Revogado pela Lei nÂº 8.630, de 25.2.1993)\n",
            "ïƒ£ Art. 288 - As taxas aprovadas para retribuir a mÃ£o de obra serÃ£o aplicadas Ã  quantidade de mercadorias movimentada por cada turma e o\n",
            "produto serÃ¡ dividido na razÃ£o de uma quota para cada trabalhador, uma para cada motorista interno do armazÃ©m, uma e meia para o feitor, uma e um\n",
            "quarto para o ajudante do feitor, uma e meia para cada motorista do guindaste do cais, uma e meia para cada conferente. (Revogado pela Lei nÂº\n",
            "8.630, de 25.2.1993)\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "c) quando o brasileiro for aprendiz, ajudante ou servente, e nÃ£o o for o estrangeiro;\n",
            "d) quando a remuneraÃ§Ã£o resultar de maior produÃ§Ã£o, para os que trabalham Ã  comissÃ£o ou por tarefa.\n",
            "ParÃ¡grafo Ãºnico - Nos casos de falta ou cessaÃ§Ã£o de serviÃ§o, a dispensa do empregado estrangeiro deve preceder Ã  de brasileiro que exerÃ§a\n",
            "funÃ§Ã£o anÃ¡loga.\n",
            "DAS RELAÃ‡Ã•ES ANUAIS DE EMPREGADOS\n",
            "ïƒ£ Art. 359 - Nenhuma empresa poderÃ¡ admitir a seu serviÃ§o empregado estrangeiro sem que este exiba a carteira de identidade de\n",
            "estrangeiro devidamente anotada .\n",
            "ParÃ¡grafo Ãºnico - A empresa Ã© obrigada a assentar no registro de empregados os dados referentes Ã  nacionalidade de qualquer empregado\n",
            "estrangeiro e o nÃºmero da respectiva carteira de identidade.\n",
            "Art. 360 - Toda empresa compreendida na enumeraÃ§Ã£o do art. 352, Â§ 1Âº, deste CapÃ­tulo, qualquer que seja o nÃºmero de seus empregados, deve\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "das tabelas aprovadas, com um acrÃ©scimo de 20% para cada hora suplementar.\n",
            "Â§ 2Âº Para ultimar a carga ou descarga dos grandes paquetes ou dos navios que estejam na iminÃªncia de perder a marÃ©, e para nÃ£o interromper o\n",
            "trabalho dos navios frigorÃ­ficos, o concessionÃ¡rio do porto poderÃ¡ executar o serviÃ§o de capatazias durantes as horas destinadas Ã s refeiÃ§Ãµes dos\n",
            "operÃ¡rios, pagando-lhes, porÃ©m, como suplemento de remuneraÃ§Ã£o, o dobro do salÃ¡rio correspondente Ã  duraÃ§Ã£o da refeiÃ§Ã£o.\n",
            "Â§ 3Âº O trabalho Ã  noite e aos domingos e feriados serÃ¡ considerado extraordinÃ¡rio e, como tal, pago com um acrÃ©scimo de 25% sobre o salÃ¡rio\n",
            "ïƒ£ Art. 292 - As taxas de capatazias serÃ£o da responsabilidade dos donos das mercadorias, os dispÃªndios extraordinÃ¡rios, porÃ©m, que por\n",
            "esse serviÃ§o pagar o concessionÃ¡rio do porto na forma do Â§ 2Âº do art. 288, e do Â§ 2Âº do art. 291 serÃ£o debitados aos armadores que houverem requisitado\n",
            "\n",
            "Pergunta: AtÃ© quantas horas extras por dia um funcionÃ¡rio pode fazer segundo a CLT?\n",
            "\n",
            "---\n",
            "ApÃ³s a resposta, adicione em uma nova linha sua confianÃ§a na resposta de 0 a 100% no formato \"ConfianÃ§a: XX%\". A confianÃ§a deve ser alta se o contexto responde diretamente Ã  pergunta.\n",
            "\n",
            "Resposta:\n",
            "A duraÃ§Ã£o normal diÃ¡ria do trabalho da mulher poderÃ¡ ser no mÃ¡ximo elevada de 2 (duas) horas, independentemente de...\n",
            "\n",
            "ConfianÃ§a: 100%\n",
            "\n",
            "\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Fonte: trabalhista.pdf\n",
            " Font\n",
            "  -> Score BLEU: 0.0081\n",
            "--------------------\n",
            "Pergunta: O que acontece se eu me demitir sem justa causa antes do fim do contrato com prazo determinado?\n",
            "  -> Resposta Esperada: Havendo termo estipulado, o empregado nÃ£o se poderÃ¡ desligar do contrato, sem justa causa, sob pena de ser obrigado a indenizar o empregador dos prejuÃ­zos que desse fato lhe resultarem.\n",
            "  -> Resposta Gerada: VocÃª Ã© um assistente jurÃ­dico no Brasil. Use APENAS o contexto a seguir para responder Ã  pergunta.\n",
            "Se a resposta nÃ£o estiver no contexto, diga \"Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\"\n",
            "Cite a fonte do documento de onde extraiu a resposta.\n",
            "\n",
            "Contexto: Fonte: trabalhista.pdf\n",
            "reconsiderar o ato, antes de seu termo, Ã  outra parte Ã© facultado aceitar ou nÃ£o a reconsideraÃ§Ã£o.\n",
            "ParÃ¡grafo Ãºnico - Caso seja aceita a reconsideraÃ§Ã£o ou continuando a prestaÃ§Ã£o depois de expirado o prazo, o contrato continuarÃ¡ a vigorar,\n",
            "como se o aviso prÃ©vio nÃ£o tivesse sido dado.\n",
            "ïƒ£ Art. 490 - O empregador que, durante o prazo do aviso prÃ©vio dado ao empregado, praticar ato que justifique a rescisÃ£o imediata do\n",
            "contrato, sujeita-se ao pagamento da remuneraÃ§Ã£o correspondente ao prazo do referido aviso, sem prejuÃ­zo da indenizaÃ§Ã£o que for devida.\n",
            "ïƒ£ Art. 491 - O empregado que, durante o prazo do aviso prÃ©vio, cometer qualquer das faltas consideradas pela lei como justas para a\n",
            "rescisÃ£o, perde o direito ao restante do respectivo prazo.\n",
            "CAPÃTULO VII\n",
            "DA ESTABILIDADE\n",
            "ïƒ£ Art. 492 - O empregado que contar mais de 10 (dez) anos de serviÃ§o na mesma empresa nÃ£o poderÃ¡ ser despedido senÃ£o por motivo\n",
            "de falta grave ou circunstÃ¢ncia de forÃ§a maior, devidamente comprovadas.\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "exercÃ­cio das suas funÃ§Ãµes, nem transferida sem causa justificada, a juizo do MinistÃ©rio do Trabalho, IndÃºstria e ComÃ©rcio, para lugar ou mister que lhe\n",
            "dificulte ou torne impossivel o desempenho da comissÃ£o ou do mandato.\n",
            "Â§ 1Âº O empregado perderÃ¡ o mandato se a transferÃªncia for por ele solicitada, ou voluntariamente aceita.\n",
            "Â§ 2Âº Considera-se de licenÃ§a nÃ£o remunerada, salvo assentimento do empregador ou clÃ¡usula contratual, o tempo em que o empregado se ausentar\n",
            "do trabalho no desempenho das funÃ§Ãµes a que se refere este artigo.\n",
            "Â§ 3Âº O empregador que despedir, suspender ou rebaixar de categoria o empregado, ou lhe reduzir o salÃ¡rio, para impedir que o mesmo se associe a\n",
            "sindicato, organize associaÃ§Ã£o sindical ou exerÃ§a os direitos inerentes Ã  condiÃ§Ã£o de sindicalizado fica sujeito Ã  penalidade prevista na alÃ­nea a, do artigo\n",
            "553, sem prejuizo da reparaÃ§Ã£o a que tiver direito o empregado.\n",
            "\n",
            "Fonte: civil.pdf\n",
            "ParÃ¡grafo Ãºnico. Se se despedir sem justa causa, terÃ¡ direito Ã  retribuiÃ§Ã£o vencida, mas responderÃ¡ por perdas e danos. O\n",
            "mesmo dar-se-Ã¡, se despedido por justa causa.\n",
            "Art. 603. Se o prestador de serviÃ§o for despedido sem justa causa, a outra parte serÃ¡ obrigada a pagar-lhe por inteiro a\n",
            "retribuiÃ§Ã£o vencida, e por metade a que lhe tocaria de entÃ£o ao termo legal do contrato.\n",
            "Art. 604. Findo o contrato, o prestador de serviÃ§o tem direito a exigir da outra parte a declaraÃ§Ã£o de que o contrato estÃ¡ findo.\n",
            "Igual direito lhe cabe, se for despedido sem justa causa, ou se tiver havido motivo justo para deixar o serviÃ§o.\n",
            "Art. 605. Nem aquele a quem os serviÃ§os sÃ£o prestados, poderÃ¡ transferir a outrem o direito aos serviÃ§os ajustados, nem o\n",
            "prestador de serviÃ§os, sem aprazimento da outra parte, dar substituto que os preste.\n",
            "Art. 606. Se o serviÃ§o for prestado por quem nÃ£o possua tÃ­tulo de habilitaÃ§Ã£o, ou nÃ£o satisfaÃ§a requisitos outros estabelecidos\n",
            "\n",
            "Fonte: trabalhista.pdf\n",
            "ïƒ£ Art. 487 - NÃ£o havendo prazo estipulado, a parte que, sem justo motivo, quiser rescindir o contrato deverÃ¡ avisar a outra da sua\n",
            "resoluÃ§Ã£o com a antecedÃªncia mÃ­nima de:\n",
            "I - 3 dias, se o empregado receber, diariamente, o seu salÃ¡rio;\n",
            "I - oito dias, se o pagamento for efetuado por semana ou tempo inferior; (RedaÃ§Ã£o dada pela Lei nÂº 1.530, de 26.12.1951)\n",
            "II - 8 dias, se o pagamento for efetuado por semana ou tempo inferior;\n",
            "II - trinta dias aos que perceberem por quinzena ou mÃªs, ou que tenham mais de 12 (doze) meses de serviÃ§o na empresa. (RedaÃ§Ã£o dada\n",
            "pela Lei nÂº 1.530, de 26.12.1951)\n",
            "Â§ 1Âº - A falta do aviso prÃ©vio por parte do empregador dÃ¡ ao empregado o direito aos salÃ¡rios correspondentes ao prazo do aviso, garantida\n",
            "sempre a integraÃ§Ã£o desse perÃ­odo no seu tempo de serviÃ§o.\n",
            "Â§ 2Âº - A falta de aviso prÃ©vio por parte do empregado dÃ¡ ao empregador o direito de descontar os salÃ¡rios correspondentes ao prazo respectivo.\n",
            "\n",
            "Fonte: civil.pdf\n",
            "sua zona, ainda que sem a sua interferÃªncia.\n",
            "Art. 715. O agente ou distribuidor tem direito Ã  indenizaÃ§Ã£o se o proponente, sem justa causa, cessar o atendimento das\n",
            "propostas ou reduzi-lo tanto que se torna antieconÃ´mica a continuaÃ§Ã£o do contrato.\n",
            "Art. 716. A remuneraÃ§Ã£o serÃ¡ devida ao agente tambÃ©m quando o negÃ³cio deixar de ser realizado por fato imputÃ¡vel ao\n",
            "proponente.\n",
            "Art. 717. Ainda que dispensado por justa causa, terÃ¡ o agente direito a ser remunerado pelos serviÃ§os Ãºteis prestados ao\n",
            "proponente, sem embargo de haver este perdas e danos pelos prejuÃ­zos sofridos.\n",
            "Art. 718. Se a dispensa se der sem culpa do agente, terÃ¡ ele direito Ã  remuneraÃ§Ã£o atÃ© entÃ£o devida, inclusive sobre os\n",
            "negÃ³cios pendentes, alÃ©m das indenizaÃ§Ãµes previstas em lei especial.\n",
            "Art. 719. Se o agente nÃ£o puder continuar o trabalho por motivo de forÃ§a maior, terÃ¡ direito Ã  remuneraÃ§Ã£o correspondente\n",
            "aos serviÃ§os realizados, cabendo esse direito aos herdeiros no caso de morte.\n",
            "\n",
            "Pergunta: O que acontece se eu me demitir sem justa causa antes do fim do contrato com prazo determinado?\n",
            "\n",
            "---\n",
            "ApÃ³s a resposta, adicione em uma nova linha sua confianÃ§a na resposta de 0 a 100% no formato \"ConfianÃ§a: XX%\". A confianÃ§a deve ser alta se o contexto responde diretamente Ã  pergunta.\n",
            "\n",
            "Resposta:\n",
            "Segundo o Art. 490, se o empregador praticar ato que justifique a rescisÃ£o imediata do contrato durante o prazo do aviso prÃ©vio, sujeita-se ao pagamento da remuneraÃ§Ã£o correspondente ao prazo do referido aviso, sem prejuÃ­zo da indenizaÃ§Ã£o que for devida.\n",
            "\n",
            "Se o empregado se demitir sem justa causa antes do fim do contrato com prazo determinado, nÃ£o hÃ¡ a possibilidade de reconsideraÃ§Ã£o do ato, pois a demissÃ£o Ã© um ato unilateral do empregado. Nesse caso, o empregado nÃ£o terÃ¡ direito ao restante do prazo do contrato, pois o contrato se finda com a demissÃ£o.\n",
            "\n",
            "ConfianÃ§a: 90%\n",
            "\n",
            "\n",
            "Com base nos documentos fornecidos, nÃ£o encontrei a informaÃ§Ã£o.\n",
            "Fonte: trabalhista.pdf\n",
            "Art. 490 - O empregador que, durante o prazo do aviso prÃ©vio dado ao empregado, praticar ato que justifique a rescisÃ£o imediata do\n",
            "contrato, sujeita-se ao pagamento da remuneraÃ§Ã£o correspondente ao prazo do referido aviso, sem prejuÃ­zo da indenizaÃ§Ã£o que for devida.\n",
            "Fonte: trabalhista.pdf\n",
            "Art. 491 - O empregado que, durante o prazo do aviso prÃ©vio, cometer qualquer das faltas consideradas pela lei como justas para a\n",
            "rescisÃ£o, perde o direito ao restante do respectivo prazo. Fonte: trabalhista.pdf\n",
            "CAPÃTULO VII\n",
            "DA ESTABILIDADE\n",
            "Fonte: trabalhista.pdf\n",
            "exercÃ­cio das suas funÃ§Ãµes, nem transferida sem causa justificada, a juizo do MinistÃ©rio do Trabalho, IndÃºstria e ComÃ©rcio, para lugar ou mister que lhe\n",
            "dificulte ou torne impossivel o desempenho da comissÃ£o ou do mandato. Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "Fonte: trabalhista.pdf\n",
            "  -> Score BLEU: 0.0097\n",
            "--------------------\n",
            "\n",
            "Score BLEU MÃ©dio: 0.0082\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "Projeto Final: Chatbot JurÃ­dico Inteligente com Classificador RAG\n",
        "\n",
        "**Autor:** Enzo GuimarÃ£es Miguel\n",
        "**Curso:** PÃ³s-GraduaÃ§Ã£o em IA, Modulo de NLP\n",
        "**Professor:** Dimmy MagalhÃ£es\n",
        "**Data:** 03 de Outubro de 2025\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Objetivo do Projeto\n",
        "\n",
        "O objetivo deste projeto foi desenvolver um protÃ³tipo completo de um chatbot jurÃ­dico inteligente. O sistema Ã© capaz de receber perguntas em linguagem natural, classificar a intenÃ§Ã£o do usuÃ¡rio e, para questÃµes jurÃ­dicas, utilizar a tÃ©cnica de GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (RAG) para encontrar respostas em uma base de conhecimento personalizada e formular uma resposta fundamentada.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Arquitetura e Ferramentas Utilizadas\n",
        "\n",
        "A soluÃ§Ã£o foi desenvolvida integralmente em um ambiente Google Colab com acesso a uma GPU T4. A escolha por uma execuÃ§Ã£o local (no Colab) em detrimento de APIs externas foi feita para cumprir os objetivos acadÃªmicos do curso, demonstrando o gerenciamento completo do pipeline de modelos.\n",
        "\n",
        "As principais tecnologias utilizadas foram:\n",
        "\n",
        "* **Linguagem:** Python 3\n",
        "* **Modelo de Linguagem (LLM):** `meta-llama/Meta-Llama-3-8B-Instruct` (quantizado em 4-bit) para classificaÃ§Ã£o de intenÃ§Ã£o e geraÃ§Ã£o de respostas.\n",
        "* **Modelo de Embedding:** `rufimelo/Legal-BERTimbau-large` para a vetorizaÃ§Ã£o semÃ¢ntica dos textos jurÃ­dicos.\n",
        "* **Banco de Dados Vetorial:** `FAISS (Facebook AI Similarity Search)` para armazenamento e busca eficiente dos vetores de texto.\n",
        "* **OrquestraÃ§Ã£o do Pipeline:** Framework `LangChain` para construir e gerenciar as cadeias de classificaÃ§Ã£o e RAG.\n",
        "* **Interface do UsuÃ¡rio (UI):** Biblioteca `Gradio` para criar a interface de chat interativa.\n",
        "* **Processamento de Dados:** `PDFPlumber` para extraÃ§Ã£o de texto dos documentos e `NLTK` para avaliaÃ§Ã£o de mÃ©tricas.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Metodologia e Pipeline\n",
        "\n",
        "O sistema funciona seguindo um pipeline bem definido, integrando as diferentes fases do projeto:\n",
        "\n",
        "1.  **IngestÃ£o de Dados:** Documentos PDF (CLT, CÃ³digo Civil, CDC) sÃ£o carregados, limpos de caracteres indesejados e divididos em `chunks` (pedaÃ§os) de 1000 caracteres com 200 de sobreposiÃ§Ã£o, utilizando a arquitetura base fornecida.\n",
        "\n",
        "2.  **VetorizaÃ§Ã£o:** Cada `chunk` Ã© processado pelo modelo `Legal-BERTimbau-large` e transformado em um vetor numÃ©rico (embedding).\n",
        "\n",
        "3.  **IndexaÃ§Ã£o:** Todos os vetores sÃ£o armazenados e indexados em um `vector store` utilizando FAISS, o que permite buscas de similaridade semÃ¢ntica de alta velocidade.\n",
        "\n",
        "4.  **Interface e InteraÃ§Ã£o:** Uma interface do Gradio recebe a pergunta do usuÃ¡rio.\n",
        "\n",
        "5.  **ClassificaÃ§Ã£o de IntenÃ§Ã£o:** A pergunta Ã© primeiro enviada para uma cadeia de classificaÃ§Ã£o que usa o Llama 3 para determinar se a pergunta Ã© `rag_required`, `general_conversation` ou `out_of_scope`.\n",
        "\n",
        "6.  **RecuperaÃ§Ã£o e GeraÃ§Ã£o (RAG):** Se classificada como `rag_required`, a pergunta Ã© usada para buscar os 5 `chunks` mais relevantes no Ã­ndice FAISS. Esses `chunks` formam o `contexto`, que Ã© entÃ£o injetado em um prompt junto com a pergunta original e enviado ao Llama 3 para formular a resposta final.\n",
        "\n",
        "7.  **Resposta ao UsuÃ¡rio:** A resposta gerada, junto com as fontes, nÃ­vel de confianÃ§a e disclaimers, Ã© exibida na interface.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Resultados da AvaliaÃ§Ã£o (Fase 5)\n",
        "\n",
        "O desempenho do sistema foi medido com scripts automatizados para avaliar separadamente o Classificador de IntenÃ§Ã£o e o pipeline de RAG (RecuperaÃ§Ã£o e GeraÃ§Ã£o).\n",
        "\n",
        "### 4.1. Desempenho do Classificador\n",
        "\n",
        "O classificador de intenÃ§Ã£o, responsÃ¡vel por direcionar a pergunta do usuÃ¡rio, foi avaliado com um dataset representativo. Os resultados de PrecisÃ£o (precision), RevocaÃ§Ã£o (recall) e F1-Score (f1-score) foram os seguintes:\n",
        "\n",
        "| Categoria              | Precision | Recall | F1-Score | Suporte (amostras) |\n",
        "|:-----------------------|:---------:|:------:|:--------:|:------------------:|\n",
        "| `calculation_required` |   1.00    |  1.00  |   1.00   |         3          |\n",
        "| `general_conversation` |   1.00    |  1.00  |   1.00   |         4          |\n",
        "| `out_of_scope`         |   1.00    |  1.00  |   1.00   |         4          |\n",
        "| `rag_required`         |   1.00    |  1.00  |   1.00   |         4          |\n",
        "|                        |           |        |          |                    |\n",
        "| **AcurÃ¡cia** |           |        | **1.00** |     **15** |\n",
        "| **MÃ©dia Macro** |   1.00    |  1.00  |   1.00   |         15         |\n",
        "| **MÃ©dia Ponderada** |   1.00    |  1.00  |   1.00   |         15         |\n",
        "\n",
        "\n",
        "\n",
        "**AnÃ¡lise do Classificador:** O classificador obteve um desempenho perfeito (100% em todas as mÃ©tricas) na amostra de teste. Isso demonstra que a abordagem de usar o LLM `Llama 3` com um prompt de poucos exemplos (*few-shot*) Ã© extremamente eficaz para distinguir as diferentes intenÃ§Ãµes do usuÃ¡rio, garantindo que a ferramenta correta (RAG, conversa geral, etc.) seja acionada para cada caso.\n",
        "\n",
        "### 4.2. Qualidade do Sistema RAG\n",
        "\n",
        "A qualidade da geraÃ§Ã£o de respostas foi avaliada com 3 perguntas-chave e suas respectivas respostas de referÃªncia. A anÃ¡lise combina uma avaliaÃ§Ã£o qualitativa (o retriever encontrou o contexto correto?) e quantitativa (o score BLEU, que mede a similaridade textual).\n",
        "\n",
        "Avaliando Respostas do RAG\n",
        "Pergunta: Qual o prazo para reclamar de vÃ­cios em produtos durÃ¡veis? -> Resposta Esperada: O direito de reclamar por vÃ­cios aparentes em produtos durÃ¡veis caduca em noventa dias. -> Resposta Gerada: Tratando-se de fornecimento de serviÃ§o e de produtos durÃ¡veis, o prazo decadencial Ã© de noventa dias, a partir da entrega efetiva do produto ou do tÃ©rmino da execuÃ§Ã£o dos serviÃ§os. -> Score BLEU: 0.0068\n",
        "Pergunta: AtÃ© quantas horas extras por dia um funcionÃ¡rio pode fazer segundo a CLT? -> Resposta Esperada: A duraÃ§Ã£o diÃ¡ria do trabalho poderÃ¡ ser acrescida de horas extras, em nÃºmero nÃ£o excedente de duas. -> Resposta Gerada: A duraÃ§Ã£o normal diÃ¡ria do trabalho da mulher poderÃ¡ ser no mÃ¡ximo elevada de 2 (duas) horas, independentemente de... -> Score BLEU: 0.0081\n",
        "Pergunta: O que acontece se eu me demitir sem justa causa antes do fim do contrato com prazo determinado? -> Resposta Esperada: Havendo termo estipulado, o empregado nÃ£o se poderÃ¡ desligar do contrato, sem justa causa, sob pena de ser obrigado a indenizar o empregador dos prejuÃ­zos que desse fato lhe resultarem. -> Resposta Gerada: Segundo o Art. 490, se o empregador praticar ato que justifique a rescisÃ£o imediata do contrato durante o prazo do aviso prÃ©vio, sujeita-se ao pagamento da remuneraÃ§Ã£o correspondente... -> Score BLEU: 0.0097\n",
        "Score BLEU MÃ©dio: 0.0082\n",
        "\n",
        "\n",
        "**AnÃ¡lise do RAG:** Os testes revelam um ponto central sobre o desempenho do sistema.\n",
        "* **Caso de Sucesso (Pergunta 1):** O sistema respondeu corretamente sobre o prazo para produtos durÃ¡veis. A anÃ¡lise do log mostra que o retriever foi bem-sucedido em encontrar o **Art. 26 do CDC**, fornecendo o contexto exato para o LLM gerar a resposta.\n",
        "* **Casos de Falha (Perguntas 2 e 3):** Para as perguntas sobre a CLT, o retriever nÃ£o encontrou os artigos corretos (Art. 59 para horas extras e Art. 480 para rescisÃ£o antecipada). Ele recuperou artigos prÃ³ximos semanticamente, mas incorretos para a pergunta especÃ­fica. Com o contexto errado, o LLM nÃ£o conseguiu responder corretamente, o que demonstra a dependÃªncia crÃ­tica da qualidade da etapa de recuperaÃ§Ã£o.\n",
        "* **Score BLEU:** A mÃ©trica BLEU resultou em valores baixos, o que Ã© esperado, pois ela mede a sobreposiÃ§Ã£o exata de palavras e sentenÃ§as. Mesmo na resposta correta, a redaÃ§Ã£o do LLM foi diferente da resposta de referÃªncia, o que penaliza o score. Isso indica que, para este caso, a **avaliaÃ§Ã£o qualitativa (verificar se a informaÃ§Ã£o estÃ¡ correta) Ã© mais importante que a pontuaÃ§Ã£o BLEU.**\n",
        "\n",
        "\n",
        "## 5. AnÃ¡lise de Casos Extremos\n",
        "\n",
        "Para avaliar a robustez e as limitaÃ§Ãµes do chatbot, foram realizados testes qualitativos com perguntas fora do padrÃ£o (\"casos extremos\"). O objetivo foi observar o comportamento do sistema diante de ambiguidades, perguntas fora de escopo e diferentes nÃ­veis de complexidade.\n",
        "\n",
        "* **Perguntas Vagas ou Abertas:** Ao receber uma pergunta ambÃ­gua como *\"fale sobre direitos do trabalhador\"*, o sistema de recuperaÃ§Ã£o (retriever) tendeu a buscar os trechos mais genÃ©ricos dos documentos, como os artigos iniciais da CLT. Consequentemente, o LLM gerou uma resposta ampla e pouco especÃ­fica. Isso demonstra que a eficÃ¡cia do RAG Ã© diretamente proporcional Ã  especificidade da pergunta do usuÃ¡rio, destacando a importÃ¢ncia de formular questÃµes claras para obter respostas detalhadas.\n",
        "\n",
        "* **Perguntas Fora de Escopo:** Em testes com perguntas claramente fora do domÃ­nio jurÃ­dico (ex: *\"Qual a previsÃ£o do tempo para Teresina?\"* ou *\"Quem vai ganhar o campeonato brasileiro?\"*), o sistema se comportou de forma ideal. O classificador de intenÃ§Ã£o, com alta precisÃ£o, identificou corretamente as perguntas como `out_of_scope` e acionou a resposta padrÃ£o, informando sua limitaÃ§Ã£o de conhecimento. Isso valida o classificador como um \"gatekeeper\" eficaz, prevenindo o uso desnecessÃ¡rio e incorreto do pipeline RAG.\n",
        "\n",
        "* **Sensibilidade do Retriever:** A anÃ¡lise revelou que o ponto mais sensÃ­vel do sistema Ã© a etapa de recuperaÃ§Ã£o de informaÃ§Ã£o. Em perguntas muito especÃ­ficas cuja resposta estava contida em um Ãºnico artigo (como a questÃ£o sobre os prazos no CDC), o sistema performou bem. No entanto, em perguntas onde os termos-chave eram mais comuns e espalhados pelo documento (como as questÃµes sobre a CLT), o retriever por vezes falhou em localizar o `chunk` mais relevante, resultando em respostas incorretas, como observado na avaliaÃ§Ã£o da Fase 5.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ConclusÃ£o\n",
        "\n",
        "Este projeto demonstrou com sucesso a construÃ§Ã£o de um chatbot jurÃ­dico de ponta a ponta, integrando componentes de classificaÃ§Ã£o de intenÃ§Ã£o, recuperaÃ§Ã£o de informaÃ§Ã£o e geraÃ§Ã£o de linguagem natural. A arquitetura, baseada na biblioteca LangChain e utilizando modelos open-source (`Llama 3`, `Legal-BERTimbau`), provou-se funcional e robusta dentro do ambiente controlado do Google Colab com GPU.\n",
        "\n",
        "Os resultados da avaliaÃ§Ã£o quantitativa foram mistos e geraram aprendizados importantes. Enquanto o classificador de intenÃ§Ã£o alcanÃ§ou performance perfeita na amostra de teste, o sistema RAG, apesar de funcional, mostrou uma forte dependÃªncia da qualidade do retriever. As falhas em recuperar o contexto correto para certas perguntas da CLT evidenciam que a busca puramente semÃ¢ntica pode ser um ponto de fragilidade em documentos densos e complexos, mesmo com o aumento do nÃºmero de chunks recuperados (`k=5`). O LLM, por sua vez, demonstrou alta capacidade de seguir instruÃ§Ãµes, respondendo corretamente quando o contexto era preciso e se recusando a responder quando nÃ£o era.\n",
        "\n",
        "Conclui-se que o protÃ³tipo Ã© um sucesso, nÃ£o apenas por funcionar, mas por permitir a identificaÃ§Ã£o clara de seus pontos fortes e fracos. Ele serve como uma excelente base para futuras melhorias, que poderiam transformar esta prova de conceito em uma ferramenta ainda mais poderosa e precisa.\n",
        "\n",
        "### Melhorias Futuras\n",
        "\n",
        "* **ImplementaÃ§Ã£o de Busca HÃ­brida:** Combinar a busca semÃ¢ntica (FAISS) com uma busca por palavra-chave (como BM25) para criar um `EnsembleRetriever`. Isso mitigaria as falhas observadas, pois termos exatos como \"horas extras\" ou \"rescisÃ£o de contrato\" seriam capturados com maior precisÃ£o.\n",
        "* **OtimizaÃ§Ã£o da EstratÃ©gia de *Chunking*:** Estudar diferentes tamanhos de `chunk` e `overlap` para encontrar um balanÃ§o ideal que evite que artigos de lei importantes sejam divididos de forma a perder seu significado semÃ¢ntico para o retriever.\n",
        "* **Refinamento do Prompt de GeraÃ§Ã£o:** Aprimorar ainda mais o prompt do RAG para que o LLM consiga extrair e sintetizar informaÃ§Ãµes de mÃºltiplos `chunks` de forma mais eficaz, mesmo que alguns deles sejam parcialmente relevantes.\n",
        "* **ImplantaÃ§Ã£o (Deploy):** Como passo final de um ciclo de desenvolvimento, o aplicativo Gradio poderia ser implantado em uma plataforma como o Hugging Face Spaces para criar uma demonstraÃ§Ã£o pÃºblica e funcional."
      ],
      "metadata": {
        "id": "57MGJYmSg20H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wgXdfrUlM3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}